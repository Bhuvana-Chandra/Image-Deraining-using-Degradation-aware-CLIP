# Image Deraining using Degradation-aware CLIP
This project explores the fusion of vision-language models (VLMs) with image restoration, focusing on the task of single-image deraining. We implement a degradation-aware CLIP (DA-CLIP) framework to adapt pre-trained CLIP embeddings for low-level vision tasks. The base restoration model uses mean-reverting stochastic differential equations (SDEs) to reconstruct clean images from rainy counterparts without relying on task-specific priors. We demonstrate that integrating DA-CLIP significantly improves PSNR, SSIM, and LPIPS metrics on the Rain100H dataset, with reduced training time and GPU memory consumption. This approach highlights the potential of VLMs in enhancing image quality under adverse conditions like rai
